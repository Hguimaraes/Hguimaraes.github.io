---
---


@inproceedings{guimaraes2022improving,
  author={Guimar{\~a}es, Heitor R. and Pimentel, Arthur and Avila, Anderson R. and Rezagholizadeh, Mehdi and Falk, Tiago H.},
  title={Improving the Robustness of DistilHuBERT to Unseen Noisy Conditions via Data Augmentation, Curriculum Learning, and Multi-Task Enhancement},
  year={2022},
  booktitle={NeurIPS 2022 Efficient Natural Language and Speech Processing Workshop},
  selected={true},
  bibtex_show={true},
  abbr={Conference},
  abstract = {Self-supervised speech representation learning aims to extract meaningful factors from the speech signal that can later be used across different downstream tasks, such as speech and/or emotion recognition. Existing models, such as HuBERT, however, can be fairly large thus may not be suitable for edge speech applications. Moreover, realistic applications typically involve speech corrupted by noise and room reverberation, hence models need to provide representations that are robust to such environmental factors. In this study, we build on the so-called DistilHuBERT model, which distils HuBERT to a fraction of its original size, with three modifications, namely: (i) augment the training data with noise and reverberation, while the student model needs to distill the clean representations from the teacher model; (ii) introduce a curriculum learning approach where increasing levels of noise are introduced as the model trains, thus helping with convergence and with the creation of more robust representations; and (iii) introduce a multi-task learning approach where the model also reconstructs the clean waveform jointly with the distillation task, thus also acting as an enhancement step to ensure additional environment robustness to the representation. Experiments on three SUPERB tasks show the advantages of the proposed method not only relative to the original DistilHuBERT, but also to the original HuBERT, thus showing the advantages of the proposed method for ``in the wild'' edge speech applications.}
}

@inproceedings{guimaraes22_l3das,
  author={Heitor R. Guimarães and Wesley Beccaro and Miguel A. Ramirez},
  title={{A Perceptual Loss Based Complex Neural Beamforming for Ambix 3D Speech Enhancement}},
  year={2022},
  booktitle={Proc. L3DAS22: Machine Learning for 3D Audio Signal Processing},
  pages={16--20},
  doi={10.21437/L3DAS.2022-4},
  selected={true},
  bibtex_show={true},
  abbr={Conference},
  abstract = {This work proposes a novel approach to B-Format AmbiX 3D speech enhancement based on the short-time Fourier transform (STFT) representation. The model is a Fully Complex Convolutional Network (FC2N) that estimates a mask to be applied to the input features. Then, a final layer is responsible for converting the B-format to a monaural representation in which we apply the inverse STFT (ISTFT) operation. For the optimization process, we use a compounded loss function, applied in the time-domain, based on the short-time objective intelligibility (STOI) metric combined with a perceptual loss on top of the wav2vec 2.0 model. The approach is applied on Task 1 of the L3DAS22 challenge, where our model achieves a score of 0.845 in the metric proposed by the challenge, using a subset of the development set as reference.}
}

@inproceedings{guimaraes2021optimizing,
  title={Optimizing Time Domain Fully Convolutional Networks for 3D Speech Enhancement in a Reverberant Environment Using Perceptual Losses},
  author={Guimar{\~a}es, Heitor R. and Beccaro, Wesley and Ram{\'\i}rez, Miguel A},
  booktitle={2021 IEEE 31st International Workshop on Machine Learning for Signal Processing (MLSP)},
  pages={1--6},
  year={2021},
  organization={IEEE},
  bibtex_show={true},
  abbr={Conference},
  abstract = {Noise in 3D reverberant environment is detrimental to several downstream applications. In this work, we propose a novel approach to 3D speech enhancement directly in the time domain through the usage of Fully Convolutional Networks (FCN) with a custom loss function based on the combination of a perceptual loss, built on top of the wav2vec model and a soft version of the short-time objective intelligibility (STOI) metric. The dataset and experiments were based on Task 1 of the L3DAS21 challenge. Our model achieves a STOI score of 0.82, word error rate (WER) equal to 0.36, and a score of 0.73 in the metric proposed by the challenge based on STOI and WER combination using as reference the development set. Our submission, based on this method, was ranked second in Task 1 of the L3DAS21 challenge.}
}

@article{GUIMARAES2020113582,
  title = {Monaural speech enhancement through deep wave-U-net},
  journal = {Expert Systems with Applications},
  volume = {158},
  pages = {113582},
  year = {2020},
  issn = {0957-4174},
  doi = {https://doi.org/10.1016/j.eswa.2020.113582},
  url = {https://www.sciencedirect.com/science/article/pii/S0957417420304061},
  author = {Heitor R. Guimarães and Hitoshi Nagano and Diego W. Silva},
  keywords = {Speech enhancement, Noise reduction, Wave-U-net, Deep learning, Signal to Noise Ratio (SNR), Word Error Rate (WER)},
  abstract = {In this paper, we present Speech Enhancement through Wave-U-Net (SEWUNet), an end-to-end approach to reduce noise from speech signals. This background context is detrimental to several downstream systems, including automatic speech recognition (ASR) and word spotting, which in turn can negatively impact end-user applications. We show that our proposal does improve signal-to-noise ratio (SNR) and word error rate (WER) compared with existing mechanisms in the literature. In the experiments, network input is a 16 kHz sample rate audio waveform corrupted by an additive noise. Our method is based on the Wave-U-Net architecture with some adaptations to our problem. Four simple enhancements are proposed and tested with ablation studies to prove their validity. In particular, we highlight the weight initialization through an autoencoder before training for the main denoising task, which leads to a more efficient use of training time and a higher performance. Through quantitative metrics, we show that our method is prefered over the classical Wiener filtering and shows a better performance than other state-of-the-art proposals.},
  bibtex_show={true},
  selected={true},
  abbr={Journal},
}

@thesis{guimaraes2018recuperaccao,
  author  = {Heitor R. Guimarães},
  title   = {Music Information Retrieval: Deep Learning Approach},
  school  = {Federal University of Rio de Janeiro (UFRJ)},
  year    = {2018},
  bibtex_show={true},
  abbr={Thesis},
}

@thesis{guimaraes2018recuperaccao,
  author  = {Heitor R. Guimarães},
  title   = {On Self-Supervised Representations for 3D Speech Enhancement},
  school  = {Universidade de São Paulo (USP)},
  year    = {2022},
  bibtex_show={true},
  abbr={Thesis},
}